{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ca83464",
   "metadata": {
    "papermill": {
     "duration": 0.010067,
     "end_time": "2024-05-17T14:53:07.114385",
     "exception": false,
     "start_time": "2024-05-17T14:53:07.104318",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Description\n",
    "Welcome to Prostate cANcer graDe Assessment (PANDA) Challenge. The task of this competition is classification of images with cancer tissue. The main challenge of this task is dealing with images of extremely high resolution and large areas of empty space. So, effective locating the areas of concern and zooming them in would be the key to reach high LB score.\n",
    "\n",
    "In this competition I found a number of public kernels performing straightforward rescaling the input images to square. However, for this particular data such an approach is not very efficient because the aspect ratio and size of provided images are not consistent and vary in a wide range. As a result, the input images are deformed to large extend in a not consistent manner uppon rescaling that limits the ability of the model to learn. Moreover, the input consists of large empty areas leading to inefficient use of GPU memory and GPU time.\n",
    "\n",
    "In this kernel I propose an alternative approach based on **Concatenate Tile pooling**. Instead of passing an entire image as an input, N tiles are selected from each image based on the number of tissue pixels (see [this kernel](https://www.kaggle.com/iafoss/panda-16x128x128-tiles) for description of data preparation and the [corresponding dataset](https://www.kaggle.com/iafoss/panda-16x128x128-tiles-data)) and passed independently through the convolutional part. The outputs of the convolutional part is concatenated in a large single map for each image preceding pooling and FC head (see image below). Since any spatial information is eliminated by the pooling layer, the Concat Tile pooling approach is nearly identical to passing an entire image through the convolutional part, excluding predictions for nearly empty regions, which do not contribute to the final prediction, and shuffle the remaining outputs into a square map of smaller size. Below I provide just a basic kernel only illustrating this approach. In my first trial I got 0.76 LB score, top 2 at the moment, and I believe it could be easily boosted to 0.80+. I hope you would enjoy my kernel, and please also check my submission kernel implementing the tile based approach.\n",
    "\n",
    "![](https://i.ibb.co/hF6LRVm/TILE.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee6c7c6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T14:53:07.130281Z",
     "iopub.status.busy": "2024-05-17T14:53:07.129921Z",
     "iopub.status.idle": "2024-05-17T14:59:36.628190Z",
     "shell.execute_reply": "2024-05-17T14:59:36.626795Z"
    },
    "papermill": {
     "duration": 389.509214,
     "end_time": "2024-05-17T14:59:36.630933",
     "exception": false,
     "start_time": "2024-05-17T14:53:07.121719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/semi-supervised-ImageNet1K-models/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnext50_32x4-ddb3e555.pth\" to /root/.cache/torch/hub/checkpoints/semi_supervised_resnext50_32x4-ddb3e555.pth\n",
      "100%|██████████| 95.8M/95.8M [00:00<00:00, 112MB/s]\n",
      "100%|██████████| 33/33 [02:01<00:00,  3.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 1.764326229239955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:36<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Loss: 1.537578355182301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:35<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Loss: 1.470201243053783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:26<00:00,  1.25it/s]\n",
      "Using cache found in /root/.cache/torch/hub/facebookresearch_semi-supervised-ImageNet1K-models_master\n",
      "100%|██████████| 33/33 [01:11<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 1.6935841350844412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:36<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Loss: 1.5432250102361043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:36<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Loss: 1.4763766960664229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:11<00:00,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.365634697036031\n",
      "[[284  30 117 151   1   1]\n",
      " [202  17 167  98  10  11]\n",
      " [ 71  14  95  79   9  31]\n",
      " [ 45   9  82  55   7  38]\n",
      " [ 53   9  53  85   4  40]\n",
      " [ 38   3  32  88   6  68]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnext50_32x4d\n",
    "import warnings\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Constants\n",
    "sz = 128\n",
    "bs = 32\n",
    "nfolds = 2\n",
    "SEED = 2020\n",
    "N = 12  # number of tiles per image\n",
    "TRAIN = '../input/panda-16x128x128-tiles-data/train/'\n",
    "LABELS = '../input/prostate-cancer-grade-assessment/train.csv'\n",
    "\n",
    "# Seed everything for reproducibility\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "# Data Preprocessing\n",
    "df = pd.read_csv(LABELS).set_index('image_id')\n",
    "files = sorted(set([p[:32] for p in os.listdir(TRAIN)]))\n",
    "df = df.loc[files]\n",
    "df = df.reset_index()\n",
    "keep_df = df.sample(frac=0.8, random_state=42)\n",
    "df = df.drop(keep_df.index)\n",
    "df = df.reset_index()\n",
    "splits = StratifiedKFold(n_splits=nfolds, random_state=SEED, shuffle=True)\n",
    "splits = list(splits.split(df, df.isup_grade))\n",
    "folds_splits = np.zeros(len(df)).astype(int)\n",
    "for i in range(nfolds): folds_splits[splits[i][1]] = i\n",
    "df['split'] = folds_splits\n",
    "\n",
    "# Normalization constants\n",
    "mean = torch.tensor([1.0 - 0.90949707, 1.0 - 0.8188697, 1.0 - 0.87795304])\n",
    "std = torch.tensor([0.36357649, 0.49984502, 0.40477625])\n",
    "\n",
    "# Custom Dataset\n",
    "class PandaDataset(data.Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.df.iloc[idx]['image_id']\n",
    "        imgs = [Image.open(os.path.join(TRAIN, f'{img_id}_{i}.png')).convert('RGB') for i in range(N)]\n",
    "        \n",
    "        if self.transform:\n",
    "            imgs = [self.transform(img) for img in imgs]\n",
    "        \n",
    "        imgs = torch.stack(imgs)\n",
    "        label = torch.tensor(self.df.iloc[idx]['isup_grade'], dtype=torch.long)\n",
    "        return imgs, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "def get_data(fold=0):\n",
    "    train_df = df[df.split != fold]\n",
    "    valid_df = df[df.split == fold]\n",
    "    \n",
    "    train_dataset = PandaDataset(train_df, transform=transform)\n",
    "    valid_dataset = PandaDataset(valid_df, transform=transform)\n",
    "    \n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=4)\n",
    "    valid_loader = data.DataLoader(valid_dataset, batch_size=bs, shuffle=False, num_workers=4)\n",
    "    \n",
    "    return train_loader, valid_loader\n",
    "\n",
    "# Model Definition\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, arch='resnext50_32x4d_ssl', n=6, pre=True):\n",
    "        super().__init__()\n",
    "        m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', arch)\n",
    "        self.enc = nn.Sequential(*list(m.children())[:-2])\n",
    "        nc = list(m.children())[-1].in_features\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(nc, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, n)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs, n, c, h, w = x.size()\n",
    "        x = x.view(-1, c, h, w)  # (bs*N, c, h, w)\n",
    "        x = self.enc(x)  # (bs*N, nc, h', w')\n",
    "        x = x.view(bs, n, x.size(1), x.size(2), x.size(3)).mean(1)  # (bs, nc, h', w')\n",
    "        x = self.head(x)  # (bs, n)\n",
    "        return x\n",
    "\n",
    "# Training\n",
    "fname = 'RNXT50'\n",
    "pred, target = [], []\n",
    "for fold in range(nfolds):\n",
    "    train_loader, valid_loader = get_data(fold)\n",
    "    model = Model()\n",
    "    model = model.cuda()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(tqdm(train_loader)):\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/3], Loss: {running_loss / len(train_loader)}')\n",
    "    \n",
    "    torch.save(model.state_dict(), f'{fname}_{fold}.pth')\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(valid_loader):\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            pred.append(outputs.cpu())\n",
    "            target.append(labels.cpu())\n",
    "\n",
    "p = torch.argmax(torch.cat(pred, 0), 1)\n",
    "t = torch.cat(target)\n",
    "print(cohen_kappa_score(t, p, weights='quadratic'))\n",
    "print(confusion_matrix(t, p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d811f5e",
   "metadata": {
    "papermill": {
     "duration": 0.034868,
     "end_time": "2024-05-17T14:59:36.700173",
     "exception": false,
     "start_time": "2024-05-17T14:59:36.665305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# OLD CODE ###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c88e7aa",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-17T14:59:36.768827Z",
     "iopub.status.busy": "2024-05-17T14:59:36.768428Z",
     "iopub.status.idle": "2024-05-17T14:59:36.773590Z",
     "shell.execute_reply": "2024-05-17T14:59:36.772615Z"
    },
    "papermill": {
     "duration": 0.042224,
     "end_time": "2024-05-17T14:59:36.775656",
     "exception": false,
     "start_time": "2024-05-17T14:59:36.733432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %reload_ext autoreload\n",
    "# %autoreload 2\n",
    "# %matplotlib inline\n",
    "\n",
    "# import fastai\n",
    "# from fastai.vision import *\n",
    "# from fastai.callbacks import SaveModelCallback\n",
    "# import os\n",
    "# #from sklearn.model_selection import KFold\n",
    "# from radam import *\n",
    "# from csvlogger import *\n",
    "# from mish_activation import *\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import cohen_kappa_score,confusion_matrix\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45b7e003",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-05-17T14:59:36.841940Z",
     "iopub.status.busy": "2024-05-17T14:59:36.841338Z",
     "iopub.status.idle": "2024-05-17T14:59:36.845272Z",
     "shell.execute_reply": "2024-05-17T14:59:36.844540Z"
    },
    "papermill": {
     "duration": 0.038407,
     "end_time": "2024-05-17T14:59:36.847185",
     "exception": false,
     "start_time": "2024-05-17T14:59:36.808778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # remove this cell if run locally\n",
    "# !mkdir 'cache'\n",
    "# !mkdir 'cache/torch'\n",
    "# !mkdir 'cache/torch/checkpoints'\n",
    "# !cp '../input/pytorch-pretrained-models/semi_supervised_resnext50_32x4-ddb3e555.pth' 'cache/torch/checkpoints/'\n",
    "# torch.hub.DEFAULT_CACHE_DIR = 'cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a26b83b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T14:59:36.907903Z",
     "iopub.status.busy": "2024-05-17T14:59:36.906903Z",
     "iopub.status.idle": "2024-05-17T14:59:36.910926Z",
     "shell.execute_reply": "2024-05-17T14:59:36.910211Z"
    },
    "papermill": {
     "duration": 0.036122,
     "end_time": "2024-05-17T14:59:36.912767",
     "exception": false,
     "start_time": "2024-05-17T14:59:36.876645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sz = 128\n",
    "# bs = 32\n",
    "# nfolds = 2\n",
    "# SEED = 2020\n",
    "# N = 12 #number of tiles per image\n",
    "# TRAIN = '../input/panda-16x128x128-tiles-data/train/'\n",
    "# LABELS = '../input/prostate-cancer-grade-assessment/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a7f6e4c",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-05-17T14:59:36.974383Z",
     "iopub.status.busy": "2024-05-17T14:59:36.973801Z",
     "iopub.status.idle": "2024-05-17T14:59:36.977683Z",
     "shell.execute_reply": "2024-05-17T14:59:36.976898Z"
    },
    "papermill": {
     "duration": 0.036759,
     "end_time": "2024-05-17T14:59:36.979554",
     "exception": false,
     "start_time": "2024-05-17T14:59:36.942795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def seed_everything(seed):\n",
    "#     random.seed(seed)\n",
    "#     os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "#     torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e693785",
   "metadata": {
    "papermill": {
     "duration": 0.030067,
     "end_time": "2024-05-17T14:59:37.039776",
     "exception": false,
     "start_time": "2024-05-17T14:59:37.009709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1227c3",
   "metadata": {
    "papermill": {
     "duration": 0.02945,
     "end_time": "2024-05-17T14:59:37.099171",
     "exception": false,
     "start_time": "2024-05-17T14:59:37.069721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Use stratified KFold split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8f2394e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T14:59:37.160051Z",
     "iopub.status.busy": "2024-05-17T14:59:37.159263Z",
     "iopub.status.idle": "2024-05-17T14:59:37.163703Z",
     "shell.execute_reply": "2024-05-17T14:59:37.162821Z"
    },
    "papermill": {
     "duration": 0.036968,
     "end_time": "2024-05-17T14:59:37.165697",
     "exception": false,
     "start_time": "2024-05-17T14:59:37.128729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(LABELS).set_index('image_id')\n",
    "# files = sorted(set([p[:32] for p in os.listdir(TRAIN)]))\n",
    "# df = df.loc[files]\n",
    "# df = df.reset_index()\n",
    "# keep_df = df.sample(frac=0.8, random_state=42)\n",
    "\n",
    "# df = df.drop(keep_df.index)\n",
    "\n",
    "# df = df.reset_index()\n",
    "# splits = StratifiedKFold(n_splits=nfolds, random_state=SEED, shuffle=True)\n",
    "# splits = list(splits.split(df,df.isup_grade))\n",
    "# folds_splits = np.zeros(len(df)).astype(np.int)\n",
    "# for i in range(nfolds): folds_splits[splits[i][1]] = i\n",
    "# df['split'] = folds_splits\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f76d5b",
   "metadata": {
    "papermill": {
     "duration": 0.029342,
     "end_time": "2024-05-17T14:59:37.225242",
     "exception": false,
     "start_time": "2024-05-17T14:59:37.195900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Check [this kernel](https://www.kaggle.com/iafoss/panda-16x128x128-tiles) for image stats. Since I use zero padding and background corresponds to 255, I invert images as 255-img when load them. Therefore, the mean value is computed as '1 - val'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1081c1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T14:59:37.286229Z",
     "iopub.status.busy": "2024-05-17T14:59:37.285943Z",
     "iopub.status.idle": "2024-05-17T14:59:37.289843Z",
     "shell.execute_reply": "2024-05-17T14:59:37.289026Z"
    },
    "papermill": {
     "duration": 0.036782,
     "end_time": "2024-05-17T14:59:37.291812",
     "exception": false,
     "start_time": "2024-05-17T14:59:37.255030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mean = torch.tensor([1.0-0.90949707, 1.0-0.8188697, 1.0-0.87795304])\n",
    "# std = torch.tensor([0.36357649, 0.49984502, 0.40477625])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4e5549",
   "metadata": {
    "papermill": {
     "duration": 0.030379,
     "end_time": "2024-05-17T14:59:37.351780",
     "exception": false,
     "start_time": "2024-05-17T14:59:37.321401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The code below (in the hidden cell) creates ImageItemList capable of loading multiple tiles of an image. It is specific for fast.ai, and pure Pytorch code would be much simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b527689e",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-05-17T14:59:37.413104Z",
     "iopub.status.busy": "2024-05-17T14:59:37.412762Z",
     "iopub.status.idle": "2024-05-17T14:59:37.418823Z",
     "shell.execute_reply": "2024-05-17T14:59:37.417972Z"
    },
    "papermill": {
     "duration": 0.038686,
     "end_time": "2024-05-17T14:59:37.420652",
     "exception": false,
     "start_time": "2024-05-17T14:59:37.381966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def open_image(fn:PathOrStr, div:bool=True, convert_mode:str='RGB', cls:type=Image,\n",
    "#         after_open:Callable=None)->Image:\n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.simplefilter(\"ignore\", UserWarning) # EXIF warning from TiffPlugin\n",
    "#         x = PIL.Image.open(fn).convert(convert_mode)\n",
    "#     if after_open: x = after_open(x)\n",
    "#     x = pil2tensor(x,np.float32)\n",
    "#     if div: x.div_(255)\n",
    "#     return cls(1.0-x) #invert image for zero padding\n",
    "\n",
    "# class MImage(ItemBase):\n",
    "#     def __init__(self, imgs):\n",
    "#         self.obj, self.data = \\\n",
    "#           (imgs), [(imgs[i].data - mean[...,None,None])/std[...,None,None] for i in range(len(imgs))]\n",
    "    \n",
    "#     def apply_tfms(self, tfms,*args, **kwargs):\n",
    "#         for i in range(len(self.obj)):\n",
    "#             self.obj[i] = self.obj[i].apply_tfms(tfms, *args, **kwargs)\n",
    "#             self.data[i] = (self.obj[i].data - mean[...,None,None])/std[...,None,None]\n",
    "#         return self\n",
    "    \n",
    "#     def __repr__(self): return f'{self.__class__.__name__} {img.shape for img in self.obj}'\n",
    "#     def to_one(self):\n",
    "#         img = torch.stack(self.data,1)\n",
    "#         img = img.view(3,-1,N,sz,sz).permute(0,1,3,2,4).contiguous().view(3,-1,sz*N)\n",
    "#         return Image(1.0 - (mean[...,None,None]+img*std[...,None,None]))\n",
    "\n",
    "# class MImageItemList(ImageList):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "    \n",
    "#     def __len__(self)->int: return len(self.items) or 1 \n",
    "    \n",
    "#     def get(self, i):\n",
    "#         fn = Path(self.items[i])\n",
    "#         fnames = [Path(str(fn)+'_'+str(i)+'.png')for i in range(N)]\n",
    "#         imgs = [open_image(fname, convert_mode=self.convert_mode, after_open=self.after_open)\n",
    "#                for fname in fnames]\n",
    "#         return MImage(imgs)\n",
    "\n",
    "#     def reconstruct(self, t):\n",
    "#         return MImage([mean[...,None,None]+_t*std[...,None,None] for _t in t])\n",
    "    \n",
    "#     def show_xys(self, xs, ys, figsize:Tuple[int,int]=(300,50), **kwargs):\n",
    "#         rows = min(len(xs),8)\n",
    "#         fig, axs = plt.subplots(rows,1,figsize=figsize)\n",
    "#         for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):\n",
    "#             xs[i].to_one().show(ax=ax, y=ys[i], **kwargs)\n",
    "#         plt.tight_layout()\n",
    "        \n",
    "\n",
    "# #collate function to combine multiple images into one tensor\n",
    "# def MImage_collate(batch:ItemsList)->Tensor:\n",
    "#     result = torch.utils.data.dataloader.default_collate(to_data(batch))\n",
    "#     if isinstance(result[0],list):\n",
    "#         result = [torch.stack(result[0],1),result[1]]\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8805dfb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T14:59:37.481085Z",
     "iopub.status.busy": "2024-05-17T14:59:37.480793Z",
     "iopub.status.idle": "2024-05-17T14:59:37.484823Z",
     "shell.execute_reply": "2024-05-17T14:59:37.483995Z"
    },
    "papermill": {
     "duration": 0.0366,
     "end_time": "2024-05-17T14:59:37.486773",
     "exception": false,
     "start_time": "2024-05-17T14:59:37.450173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_data(fold=0):\n",
    "#     return (MImageItemList.from_df(df, path='.', folder=TRAIN, cols='image_id')\n",
    "#       .split_by_idx(df.index[df.split == fold].tolist())\n",
    "#       .label_from_df(cols=['isup_grade'])\n",
    "#       .transform(get_transforms(flip_vert=True,max_rotate=15),size=sz,padding_mode='zeros')\n",
    "#       .databunch(bs=bs,num_workers=4))\n",
    "\n",
    "# data = get_data(0)\n",
    "# data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1257317",
   "metadata": {
    "papermill": {
     "duration": 0.029685,
     "end_time": "2024-05-17T14:59:37.545897",
     "exception": false,
     "start_time": "2024-05-17T14:59:37.516212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744861f7",
   "metadata": {
    "papermill": {
     "duration": 0.029744,
     "end_time": "2024-05-17T14:59:37.647011",
     "exception": false,
     "start_time": "2024-05-17T14:59:37.617267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The code below implements Concat Tile pooling idea. As a backbone I use [Semi-Weakly Supervised ImageNet pretrained ResNeXt50 model](https://github.com/facebookresearch/semi-supervised-ImageNet1K-models), which worked for me quite well in a number of previous competitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7c9f5a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T14:59:37.709160Z",
     "iopub.status.busy": "2024-05-17T14:59:37.708816Z",
     "iopub.status.idle": "2024-05-17T14:59:37.713804Z",
     "shell.execute_reply": "2024-05-17T14:59:37.712856Z"
    },
    "papermill": {
     "duration": 0.038973,
     "end_time": "2024-05-17T14:59:37.715730",
     "exception": false,
     "start_time": "2024-05-17T14:59:37.676757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class Model(nn.Module):\n",
    "#     def __init__(self, arch='resnext50_32x4d_ssl', n=6, pre=True):\n",
    "#         super().__init__()\n",
    "#         m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', arch)\n",
    "#         self.enc = nn.Sequential(*list(m.children())[:-2])       \n",
    "#         nc = list(m.children())[-1].in_features\n",
    "#         self.head = nn.Sequential(AdaptiveConcatPool2d(),Flatten(),nn.Linear(2*nc,512),\n",
    "#                             Mish(),nn.BatchNorm1d(512), nn.Dropout(0.5),nn.Linear(512,n))\n",
    "        \n",
    "#     def forward(self, *x):\n",
    "#         shape = x[0].shape\n",
    "#         n = len(x)\n",
    "#         x = torch.stack(x,1).view(-1,shape[1],shape[2],shape[3])\n",
    "#         #x: bs*N x 3 x 128 x 128\n",
    "#         x = self.enc(x)\n",
    "#         #x: bs*N x C x 4 x 4\n",
    "#         shape = x.shape\n",
    "#         #concatenate the output for tiles into a single map\n",
    "#         x = x.view(-1,n,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous()\\\n",
    "#           .view(-1,shape[1],shape[2]*n,shape[3])\n",
    "#         #x: bs x C x N*4 x 4\n",
    "#         x = self.head(x)\n",
    "#         #x: bs x n\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f57e936",
   "metadata": {
    "papermill": {
     "duration": 0.029305,
     "end_time": "2024-05-17T14:59:37.774185",
     "exception": false,
     "start_time": "2024-05-17T14:59:37.744880",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bde2284c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T14:59:37.834717Z",
     "iopub.status.busy": "2024-05-17T14:59:37.834364Z",
     "iopub.status.idle": "2024-05-17T14:59:37.839269Z",
     "shell.execute_reply": "2024-05-17T14:59:37.838378Z"
    },
    "papermill": {
     "duration": 0.037315,
     "end_time": "2024-05-17T14:59:37.841130",
     "exception": false,
     "start_time": "2024-05-17T14:59:37.803815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fname = 'RNXT50'\n",
    "# pred,target = [],[]\n",
    "# for fold in range(nfolds):\n",
    "#     data = get_data(fold)\n",
    "#     model = Model()\n",
    "#     learn = Learner(data, model, loss_func=nn.CrossEntropyLoss(), opt_func=Over9000, \n",
    "#                 metrics=[KappaScore(weights='quadratic')]).to_fp16()\n",
    "#     logger = CSVLogger(learn, f'log_{fname}_{fold}')\n",
    "#     learn.clip_grad = 1.0\n",
    "#     learn.split([model.head])\n",
    "#     learn.unfreeze()\n",
    "\n",
    "#     learn.fit_one_cycle(3, max_lr=1e-3, div_factor=100, pct_start=0.0, \n",
    "#       callbacks = [SaveModelCallback(learn,name=f'model',monitor='kappa_score')])\n",
    "#     torch.save(learn.model.state_dict(), f'{fname}_{fold}.pth')\n",
    "    \n",
    "#     learn.model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for step, (x, y) in progress_bar(enumerate(data.dl(DatasetType.Valid)),\n",
    "#                                      total=len(data.dl(DatasetType.Valid))):\n",
    "#             p = learn.model(*x)\n",
    "#             pred.append(p.float().cpu())\n",
    "#             target.append(y.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "041f1bad",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2024-05-17T14:59:37.905578Z",
     "iopub.status.busy": "2024-05-17T14:59:37.905226Z",
     "iopub.status.idle": "2024-05-17T14:59:37.908990Z",
     "shell.execute_reply": "2024-05-17T14:59:37.908215Z"
    },
    "papermill": {
     "duration": 0.038559,
     "end_time": "2024-05-17T14:59:37.910967",
     "exception": false,
     "start_time": "2024-05-17T14:59:37.872408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# p = torch.argmax(torch.cat(pred,0),1)\n",
    "# t = torch.cat(target)\n",
    "# print(cohen_kappa_score(t,p,weights='quadratic'))\n",
    "# print(confusion_matrix(t,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "898b1922",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-05-17T14:59:37.972107Z",
     "iopub.status.busy": "2024-05-17T14:59:37.971829Z",
     "iopub.status.idle": "2024-05-17T14:59:37.975620Z",
     "shell.execute_reply": "2024-05-17T14:59:37.974729Z"
    },
    "papermill": {
     "duration": 0.036119,
     "end_time": "2024-05-17T14:59:37.977490",
     "exception": false,
     "start_time": "2024-05-17T14:59:37.941371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -r 'cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3347704",
   "metadata": {
    "papermill": {
     "duration": 0.029674,
     "end_time": "2024-05-17T14:59:38.037539",
     "exception": false,
     "start_time": "2024-05-17T14:59:38.007865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1126921,
     "sourceId": 18647,
     "sourceType": "competition"
    },
    {
     "datasetId": 624783,
     "sourceId": 1113957,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 54791,
     "sourceId": 1127417,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 21342545,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 22581004,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 47125891,
     "sourceType": "kernelVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 396.419915,
   "end_time": "2024-05-17T14:59:40.615219",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-17T14:53:04.195304",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
