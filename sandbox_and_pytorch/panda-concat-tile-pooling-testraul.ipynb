{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":18647,"databundleVersionId":1126921,"sourceType":"competition"},{"sourceId":863262,"sourceType":"datasetVersion","datasetId":458222},{"sourceId":1115430,"sourceType":"datasetVersion","datasetId":625794},{"sourceId":8367274,"sourceType":"datasetVersion","datasetId":4973853},{"sourceId":22581004,"sourceType":"kernelVersion"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Description\nThis kernel performs inference for [PANDA concat tile pooling starter](https://www.kaggle.com/iafoss/panda-concat-fast-ai-starter) kernel with use of multiple models and 8 fold TTA. Check it for more training details. The image preprocessing pipline is provided [here](https://www.kaggle.com/iafoss/panda-16x128x128-tiles).","metadata":{}},{"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import transforms, datasets\nimport os\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import cohen_kappa_score, confusion_matrix\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport random\nimport numpy as np\nimport pandas as pd\nimport warnings\nfrom pathlib import Path\nfrom typing import Callable, Tuple\nimport torch.utils.data\nimport matplotlib.pyplot as plt\nimport PIL.Image\nfrom torch.utils.data import DataLoader, Dataset\nimport os\nimport cv2\nimport skimage.io\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport glob\nimport pandas as pd\n\n\ntorch.__version__","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:55:56.355269Z","iopub.execute_input":"2024-05-09T14:55:56.355706Z","iopub.status.idle":"2024-05-09T14:55:56.470613Z","shell.execute_reply.started":"2024-05-09T14:55:56.355680Z","shell.execute_reply":"2024-05-09T14:55:56.469715Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'2.1.2'"},"metadata":{}}]},{"cell_type":"code","source":"df_test = pd.read_csv(\"../input/prostate-cancer-grade-assessment/test.csv\")\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:55:56.471655Z","iopub.execute_input":"2024-05-09T14:55:56.471936Z","iopub.status.idle":"2024-05-09T14:55:56.590557Z","shell.execute_reply.started":"2024-05-09T14:55:56.471913Z","shell.execute_reply":"2024-05-09T14:55:56.589610Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                           image_id data_provider\n0  005700be7e06878e6605e7a5a39de1b2       radboud\n1  005c6e8877caf724c600fdce5d417d40    karolinska\n2  0104f76634ff89bfff1ef0804a95c380       radboud","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>data_provider</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>005700be7e06878e6605e7a5a39de1b2</td>\n      <td>radboud</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005c6e8877caf724c600fdce5d417d40</td>\n      <td>karolinska</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0104f76634ff89bfff1ef0804a95c380</td>\n      <td>radboud</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"img_path = \"../input/panda-16x128x128-tiles-data/test\"\nimg_id = list(df_test[\"image_id\"])\nimg_files = glob.glob(img_path + f\"/{img_id[1]}\" + \"*\")","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:55:58.384405Z","iopub.execute_input":"2024-05-09T14:55:58.384797Z","iopub.status.idle":"2024-05-09T14:55:58.481804Z","shell.execute_reply.started":"2024-05-09T14:55:58.384768Z","shell.execute_reply":"2024-05-09T14:55:58.480880Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def get_df():\n    data = {\"image_id\": []}\n    img_path = \"../input/panda-16x128x128-tiles-data/test\"\n    img_ids = list(df_test[\"image_id\"])\n    for i in tqdm(range(len(img_ids))):\n        img_id = img_ids[i]\n        img_files = []\n        for i in range(16):\n            img_files.append(f\"{img_id}\"+f\"_{i}\"+\".png\")\n        data[\"image_id\"].extend(img_files)\n        \n        \n    return data","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:55:59.106110Z","iopub.execute_input":"2024-05-09T14:55:59.106914Z","iopub.status.idle":"2024-05-09T14:55:59.203599Z","shell.execute_reply.started":"2024-05-09T14:55:59.106882Z","shell.execute_reply":"2024-05-09T14:55:59.202627Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def to_pandas(data):\n    df = pd.DataFrame(data, columns = [\"image_id\"])\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:56:00.025918Z","iopub.execute_input":"2024-05-09T14:56:00.026250Z","iopub.status.idle":"2024-05-09T14:56:00.125498Z","shell.execute_reply.started":"2024-05-09T14:56:00.026226Z","shell.execute_reply":"2024-05-09T14:56:00.124654Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data = get_df()\ndf_new = to_pandas(data)\n\ndf_new.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:56:01.068096Z","iopub.execute_input":"2024-05-09T14:56:01.068701Z","iopub.status.idle":"2024-05-09T14:56:01.186389Z","shell.execute_reply.started":"2024-05-09T14:56:01.068671Z","shell.execute_reply":"2024-05-09T14:56:01.185497Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50f248f5401343dc9550e09f21c3b97f"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                 image_id\n0  005700be7e06878e6605e7a5a39de1b2_0.png\n1  005700be7e06878e6605e7a5a39de1b2_1.png\n2  005700be7e06878e6605e7a5a39de1b2_2.png\n3  005700be7e06878e6605e7a5a39de1b2_3.png\n4  005700be7e06878e6605e7a5a39de1b2_4.png","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>005700be7e06878e6605e7a5a39de1b2_0.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005700be7e06878e6605e7a5a39de1b2_1.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>005700be7e06878e6605e7a5a39de1b2_2.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>005700be7e06878e6605e7a5a39de1b2_3.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>005700be7e06878e6605e7a5a39de1b2_4.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def get_img_tiles(image_list):\n    img_rows = []\n    rc = 0\n    for i in range(3):\n        img1 = cv2.imread(image_list[rc + 0], cv2.COLOR_BGR2RGB)\n        img2 = cv2.imread(image_list[rc + 1], cv2.COLOR_BGR2RGB)\n        img3 = cv2.imread(image_list[rc + 2], cv2.COLOR_BGR2RGB)\n     \n        \n        # Check if any image is None\n        if any(img is None for img in [img1, img2, img3]):\n            print(\"Some images could not be loaded properly. Skipping concatenation.\")\n            return \"wrong\"\n        \n        img_row = np.concatenate((img1, img2, img3), axis=1)\n        rc += 3\n        img_rows.append(img_row)\n    img_stacked = np.concatenate(img_rows, axis=0)\n    return img_stacked","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:44:57.632371Z","iopub.execute_input":"2024-05-09T14:44:57.632783Z","iopub.status.idle":"2024-05-09T14:44:57.686262Z","shell.execute_reply.started":"2024-05-09T14:44:57.632752Z","shell.execute_reply":"2024-05-09T14:44:57.685357Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:44:59.203081Z","iopub.execute_input":"2024-05-09T14:44:59.203812Z","iopub.status.idle":"2024-05-09T14:44:59.255474Z","shell.execute_reply.started":"2024-05-09T14:44:59.203781Z","shell.execute_reply":"2024-05-09T14:44:59.254422Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import warnings\n\n# Ignore all warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Define a list to store example tiles\nexample_tiles_list = []\n\n# Split the DataFrame into chunks of size 16 and process each chunk\nfor i in tqdm(range(0, len(df_new), 16)):\n    example_chunk = df_new[\"image_id\"].iloc[i:i+12]\n    example_chunk = list(example_chunk.map(lambda x: os.path.join(\"../input/panda-16x128x128-tiles-data/test\", x)))\n\n    # Concatenate the tiles\n    example_tile = get_img_tiles(example_chunk)\n    if str(example_tile) == \"wrong\":\n        continue\n    example_tiles_list.append(example_tile)\n    \n\nprint(len(example_tiles_list))\n\n# Define a custom dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, data, transform=None):\n        self.data = data\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img = self.data[idx]\n        if self.transform:\n            img = self.transform(img)\n        return img\n\n# Define transformations\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n])\n\n# Create the custom dataset\ncustom_dataset = CustomDataset(example_tiles_list, transform=transform)\n\ntest_size = len(custom_dataset)\ntest_dataset = torch.utils.data.random_split(custom_dataset, [test_size])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:45:00.150695Z","iopub.execute_input":"2024-05-09T14:45:00.151378Z","iopub.status.idle":"2024-05-09T14:45:00.235154Z","shell.execute_reply.started":"2024-05-09T14:45:00.151346Z","shell.execute_reply":"2024-05-09T14:45:00.234275Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"  0%|          | 0/3 [00:00<?, ?it/s][ WARN:0@11.534] global loadsave.cpp:248 findDecoder imread_('../input/panda-16x128x128-tiles-data/test/005700be7e06878e6605e7a5a39de1b2_0.png'): can't open/read file: check file path/integrity\n[ WARN:0@11.535] global loadsave.cpp:248 findDecoder imread_('../input/panda-16x128x128-tiles-data/test/005700be7e06878e6605e7a5a39de1b2_1.png'): can't open/read file: check file path/integrity\n[ WARN:0@11.535] global loadsave.cpp:248 findDecoder imread_('../input/panda-16x128x128-tiles-data/test/005700be7e06878e6605e7a5a39de1b2_2.png'): can't open/read file: check file path/integrity\n[ WARN:0@11.535] global loadsave.cpp:248 findDecoder imread_('../input/panda-16x128x128-tiles-data/test/005c6e8877caf724c600fdce5d417d40_0.png'): can't open/read file: check file path/integrity\n[ WARN:0@11.536] global loadsave.cpp:248 findDecoder imread_('../input/panda-16x128x128-tiles-data/test/005c6e8877caf724c600fdce5d417d40_1.png'): can't open/read file: check file path/integrity\n[ WARN:0@11.536] global loadsave.cpp:248 findDecoder imread_('../input/panda-16x128x128-tiles-data/test/005c6e8877caf724c600fdce5d417d40_2.png'): can't open/read file: check file path/integrity\n[ WARN:0@11.536] global loadsave.cpp:248 findDecoder imread_('../input/panda-16x128x128-tiles-data/test/0104f76634ff89bfff1ef0804a95c380_0.png'): can't open/read file: check file path/integrity\n[ WARN:0@11.536] global loadsave.cpp:248 findDecoder imread_('../input/panda-16x128x128-tiles-data/test/0104f76634ff89bfff1ef0804a95c380_1.png'): can't open/read file: check file path/integrity\n100%|██████████| 3/3 [00:00<00:00, 434.94it/s][ WARN:0@11.536] global loadsave.cpp:248 findDecoder imread_('../input/panda-16x128x128-tiles-data/test/0104f76634ff89bfff1ef0804a95c380_2.png'): can't open/read file: check file path/integrity\n","output_type":"stream"},{"name":"stdout","text":"Some images could not be loaded properly. Skipping concatenation.\nSome images could not be loaded properly. Skipping concatenation.\nSome images could not be loaded properly. Skipping concatenation.\n0\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"import timm\nfrom torch.nn import AdaptiveAvgPool2d, Flatten, Linear\nfrom mish_activation import Mish \n\nclass AdaptiveConcatPool2d(nn.Module):\n    def __init__(self, output_size=(1, 1)):\n        super(AdaptiveConcatPool2d, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(output_size)\n        self.max_pool = nn.AdaptiveMaxPool2d(output_size)\n\n    def forward(self, x):\n        return torch.cat([self.avg_pool(x), self.max_pool(x)], 1)\n\nclass Model(nn.Module):\n    def __init__(self, arch='resnext50_32x4d', n=6, pre=True):\n        super().__init__()\n        # Load ResNet model using timm\n        m = timm.create_model(arch, pretrained=pre)\n        self.enc = nn.Sequential(*list(m.children())[:-2])\n        nc = list(m.children())[-1].in_features\n        self.head = nn.Sequential(AdaptiveConcatPool2d(), Flatten(), nn.Linear(2 * nc, 512),\n                                  Mish(), nn.BatchNorm1d(512), nn.Dropout(0.5), nn.Linear(512, n))\n        \n    def forward(self, *x):\n        shape = x[0].shape\n        n = len(x)\n        x = torch.stack(x, 1).view(-1, shape[1], shape[2], shape[3])\n        # x: bs*N x 3 x 128 x 128\n        x = self.enc(x)\n        # x: bs*N x C x 4 x 4\n        shape = x.shape\n        # concatenate the output for tiles into a single map\n        x = x.view(-1, n, shape[1], shape[2], shape[3]).permute(0, 2, 1, 3, 4).contiguous() \\\n            .view(-1, shape[1], shape[2] * n, shape[3])\n        # x: bs x C x N*4 x 4\n        x = self.head(x)\n        # x: bs x n\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:46:32.382809Z","iopub.execute_input":"2024-05-09T14:46:32.383970Z","iopub.status.idle":"2024-05-09T14:46:33.884969Z","shell.execute_reply.started":"2024-05-09T14:46:32.383930Z","shell.execute_reply":"2024-05-09T14:46:33.883976Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# model = Model()\n# pretrained_weights_path = '../input/publicpandasetraul/resnext50_32x4d_final.pth'\n\n# # Load the pre-trained weights into the model\n# model.load_state_dict(torch.load(pretrained_weights_path))\n\n# # Ensure the model is in evaluation mode\n# model.eval()\nprint(\"modelbefore\")\nmodel = torch.load('/kaggle/input/modelagain/resnext50_32x4d_final (1).pth')\nprint(\"modelafter\")","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:46:33.886735Z","iopub.execute_input":"2024-05-09T14:46:33.887302Z","iopub.status.idle":"2024-05-09T14:46:35.232701Z","shell.execute_reply.started":"2024-05-09T14:46:33.887266Z","shell.execute_reply":"2024-05-09T14:46:35.231735Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"modelbefore\nmodelafter\n","output_type":"stream"}]},{"cell_type":"code","source":"pred = []\n\ntry:\n    for image in test_dataset:\n        image = images.to(device)  # Move data to GPU\n        output = model(image)\n        pred.append(output.cpu())\nexcept:\n    pass\n\n# Concatenate predictions and targets\ntry:\n    pred = torch.cat(pred, 0)\n    \nexcept:\n    pass\n\n\n# Calculate Kappa score and confusion matrix\ntry:\n    p = torch.argmax(pred, 1)\n    pred.append(p)\nexcept:\n    p = 0\n    pred.append(p)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:29:58.965962Z","iopub.execute_input":"2024-05-09T14:29:58.966670Z","iopub.status.idle":"2024-05-09T14:29:59.083235Z","shell.execute_reply.started":"2024-05-09T14:29:58.966630Z","shell.execute_reply":"2024-05-09T14:29:59.082325Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"df_test.drop(columns=['data_provider'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:29:59.449292Z","iopub.execute_input":"2024-05-09T14:29:59.450260Z","iopub.status.idle":"2024-05-09T14:29:59.561492Z","shell.execute_reply.started":"2024-05-09T14:29:59.450229Z","shell.execute_reply":"2024-05-09T14:29:59.560724Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"df_test","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:30:00.680018Z","iopub.execute_input":"2024-05-09T14:30:00.680382Z","iopub.status.idle":"2024-05-09T14:30:00.795771Z","shell.execute_reply.started":"2024-05-09T14:30:00.680352Z","shell.execute_reply":"2024-05-09T14:30:00.794790Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"                           image_id\n0  005700be7e06878e6605e7a5a39de1b2\n1  005c6e8877caf724c600fdce5d417d40\n2  0104f76634ff89bfff1ef0804a95c380","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>005700be7e06878e6605e7a5a39de1b2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005c6e8877caf724c600fdce5d417d40</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0104f76634ff89bfff1ef0804a95c380</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"while len(p) < len(df_test):\n    p.append(0)  \n\ndf_test['isup_grade'] = p","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:30:03.346269Z","iopub.execute_input":"2024-05-09T14:30:03.347112Z","iopub.status.idle":"2024-05-09T14:30:03.457976Z","shell.execute_reply.started":"2024-05-09T14:30:03.347078Z","shell.execute_reply":"2024-05-09T14:30:03.457033Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"df_test","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:30:05.144097Z","iopub.execute_input":"2024-05-09T14:30:05.144434Z","iopub.status.idle":"2024-05-09T14:30:05.261979Z","shell.execute_reply.started":"2024-05-09T14:30:05.144409Z","shell.execute_reply":"2024-05-09T14:30:05.260922Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"                           image_id  isup_grade\n0  005700be7e06878e6605e7a5a39de1b2           0\n1  005c6e8877caf724c600fdce5d417d40           0\n2  0104f76634ff89bfff1ef0804a95c380           0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>isup_grade</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>005700be7e06878e6605e7a5a39de1b2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005c6e8877caf724c600fdce5d417d40</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0104f76634ff89bfff1ef0804a95c380</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test.to_csv(\"submission.csv\", index=False)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:30:06.091161Z","iopub.execute_input":"2024-05-09T14:30:06.091814Z","iopub.status.idle":"2024-05-09T14:30:06.207256Z","shell.execute_reply.started":"2024-05-09T14:30:06.091784Z","shell.execute_reply":"2024-05-09T14:30:06.205925Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"                           image_id  isup_grade\n0  005700be7e06878e6605e7a5a39de1b2           0\n1  005c6e8877caf724c600fdce5d417d40           0\n2  0104f76634ff89bfff1ef0804a95c380           0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>isup_grade</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>005700be7e06878e6605e7a5a39de1b2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005c6e8877caf724c600fdce5d417d40</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0104f76634ff89bfff1ef0804a95c380</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#print(model)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:30:18.045068Z","iopub.execute_input":"2024-05-09T14:30:18.045435Z","iopub.status.idle":"2024-05-09T14:30:18.159099Z","shell.execute_reply.started":"2024-05-09T14:30:18.045406Z","shell.execute_reply":"2024-05-09T14:30:18.157859Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}